# 💡 작업 배경

그 동안 프로젝트를 진행할 때 Vercel로 배포를 했었는데 몇가지 아쉬운 내용들이 있어 정리를 해보았다.

## ✔️ Vercel의 장점
### 1. 사용이 편하다.
- 깃허브에 푸시만 하면 자동으로 배포되고, 도메인 연결되는 작업은 처음 배포해보는사람도 금방 적용할 수 있을만큼 간단했다.

## ❌ Vercel의 단점
### 1. 자유도가 부족하다.
- 기본 설정은 Vercel 시스템을 그대로 따라야 하기 때문에 커스터마이징이 제한적이다.

### 2. 협업 환경이 어렵다.
- 백엔드팀이 AWS를 사용하는 경우가 많은데, Vercel 배포 시 공통된 이해를 바탕으로 한 협업환경 구성이 어려울 것이라고 생각했다.

### 3. 실무 경험의 한계
- 완성된 서비스만 사용하다보니 실제 인프라에 대한 깊은 이해가 부족하다고 느꼈다.
- CICD를 직접 경험해본다면 웹 서비스 운영에 대해 한층 더 깊이 이해할 수 있을 것이라고 생각했다.

---
<br></br>

# ✨ CI/CD 구현 목표
이번 작업의 핵심 목표는 "완성되어있는 서비스를 바로 사용하는것이 아닌, 구조를 직접 설계하고 코드 작성해보기" 였다.

CICD를 직접 경험해보면 웹 서비스 운영에 대해 한층 더 깊이 이해할 수 있을 것이라고 생각했다.

가장 유명한 서비스인 AWS를 활용 해보기로 했다.

# 💡 AWS 서비스 선정
AWS에서는 다양한 서비스들을 제공하고있었고, 내 프로젝트에 어떤 서비스가 적합할 지 고민해봐야 했다.

## 🔍 고려했던 AWS 서비스들
- S3: 정적 파일 호스팅
- EC2: 가상 서버 인스턴스
- CodeDeploy: 자동 배포 서비스
- CodePipeline: CI/CD 파이프라인
- Amplify: 풀스택 애플리케이션 배포

## ❓ 나의 프로젝트 특성
- 프레임워크: Next.js(서버환경 필요)

## ✔️ 최종 선정

서버환경이 필요한 프로젝트이기 때문에 S3는 사용이 불가능했다.

또 CodeDeploy와 CodePipeline을 사용하면 쉽게 배포할 수 있으며 CICD도 사용 가능했지만, 하나부터 열까지 직접 구현해보고싶었기에 EC2를 사용해 배포를 해보기로 했다.

---
<br></br>

# 💡 구현 과정

## 🚀 첫 번째 시도 - EC2에서 직접 빌드하기
처음 구상한 구조는 정말 단순했다.
```
github action 실행 => EC2 인스턴스 접속 => git Repo에서 pull => 의존성 설치 및 빌드 실행 => PM2 프로세스 실행
```
하지만 이 방식에는 치명적인 단점이 있었다.

### ❌ 문제점
#### ⚠️ EC2 프리티어 메모리의 부족
안그래도 메모리가 부족한데(1GB) 프로젝트 빌드 시 메모리를 너무 많이 사용했다.

실제로 로컬 환경에서 직접 빌드는 해보면 알 수 있지만 기본 400mb는 가볍게 먹고 들어가고, 1GB를 넘길때도 있었다.

이것은 빌드 도중 OOM 을 유발했고 서비스 STOP 및 불필요한 서버 재가동 작업을 해줘야했다.

#### ⚠️ 과한 디스크 사용량

원본소스코드와 프로세스 실행에 필요한 빌드파일들 모두 서버에 저장되는 방식이다 보니 디스크 사용량도 결코 적지 않았다.

#### ⚠️ 오래걸리는 빌드 시간

EC2 서버의 메모리를 사용하다보니 프로젝트의 규모가 크지 않아도 빌드 시간이 오래 걸리는 문제가 있었다.

## 🔧 문제점 개선 - 빌드 파일을 EC2서버에 업로드하기

근본적인 원인은 "EC2 인스턴스에서 직접 Build 실행" 하는 구조에 있었다.

이 문제를 해결하기 위해 github action이 실행된 후 즉시 build하며 build된 파일만 EC2 서버에 업로드 하는 방식에 대해 검토해보았다.

```
github action 실행 => npm ci / npm run build => EC2 서버 업로드 => PM2 프로세스 실행
```

이 방식을 적용하면 EC2 서버가 메모리를 불필요하게 많이 사용하는 문제를 막을 수 있고, 소스코드는 업로드 하지 않으므로 디스크도 절약할 수 있었다.

## ✨ 추가 개선 - production용 node modules만 서버에 업로드 하기

실제 프로덕션에는 `devDependencies`는 필요가 없기 때문에 프로덕션용 패키지만 서버에 업로드 하는 방식을 사용하고자 했다.

```
npm install --production
```
위의 명령어를 이용해 프로덕션 용 패키지만 별도로 설치가 가능한데, 여기서 또 문제가 발생했다.
```
action 실행 => npm install => npm run build => rm -rf node_modules(의존성 삭제) => npm install --production
```
정리하자면, 프로젝트 빌드 시의 검증을 위해 전체 패키지를 이미 한번 설치했는데, EC2 서버 업로드를 위해 프로덕션용 패키지 설치를 한번 더 실행하게 되면 빌드 시간이 더 늘어나버리는 문제였다.

이 문제를 해결하기 위한 방법을 찾아보았고, 이미 설치된 node modules에서 devDependencies만 삭제하는 명령어를 알게 되었다.

이 명령어는 기존에 이미 설치되어있는 node modules에서 개발 의존성을 제거하는 명령어이다.
```
npm prune --omit=dev
```
그러니까 새로 설치하는 것이 아니라 기존에 설치되어있던 파일을 삭제하는 것이므로 작업 시간을 훨씬 더 단축할 수 있었다.

변경 전 용량
```
ubuntu@ip-172-31-43-170:/var/www/preview/chiyoung-fix-auth$ du -sh .[^.]* * 2>/dev/null | sort -hr
925M    node_modules
213M    .next
1.5M    public
616K    package-lock.json
8.0K    config
4.0K    package.json
4.0K    next.config.ts
```

변경 후 용량
```
ubuntu@ip-172-31-43-170:/var/www/preview/chiyoung-fix-auth$ du -sh .[^.]* * | sort -hr
559M    node_modules
213M    .next
1.5M    public
616K    package-lock.json
8.0K    config
4.0K    package.json
4.0K    next.config.js
```

약 350M 개선된 것을 볼 수 있다.

## ✨ 추가 개선 2 - 빌드 파일 압축하기

첫번째 개선 내용에서 node_modules 최적화를 진행했지만, 여전히 900Mb 가까이 되는것을 알 수 있다.

현재 EC2 서버에 업로드하는 파일들은 빌드파일, node modules, public 등으로 구성되어있다.

특히나 Next.js 프로젝트는 모듈 크기가 크다.

node_modules 용량 순 정렬 검색 결과를 확인해보면, next 관련 패키지 용량만 거의 420M가 되는것을 볼 수 있다.

```
ubuntu@ip-172-31-43-170:~/project-app$ du -sh node_modules/* | sort -hr | head -20
272M    node_modules/@next
150M    node_modules/next
```

이런 경우 인터넷이 느린 환경에서는 작업 시간이 지연될 수 있고, AWS 네트워크 전송 비용에도 불리 할 것이라고 생각했다.

따라서 파일들을 압축해서 EC2 서버에 업로드 후, 압축 해제해서 사용하는 방법을 시도해보았다.

```
# 압축
cd deploy-package
tar -czf ../production-app.tar.gz --exclude='node_modules/*/.cache' --exclude='node_modules/*/coverage' .
```
deploy-package 디렉토리는 /public, /.next 등 프로세스 실행에 필요한 파일들을 모아놓은 임시 디렉토리이고, 이 디렉토리에서 압축을 진행하는 방식이다.

이 때 /.cache 와 /coverage는 압축 대상에서 제외하여 용량 최적화를 조금 더 진행 해주었다.

linux 환경에서 tar는 다수의 파일을 디렉토리 구조, 파일 속성 등을 보존하면서 하나의 파일로 묶는데 사용되는 파일 형식이다.

| 명령어 | 압축 방식 | 압축 시간 | CPU/메모리 사용량 | 압축률 | 파일 확장자 | 용도 |
|--------|-----------|-----------|-------------------|--------|-------------| --- |
| tar cf | 압축 없음 (묶기만) | 매우 빠름 | 매우 적음 | 거의 없음 | .tar | 단순 묶기 |
| tar czf | gzip 압축 | 보통 | 보통 | 중간 (30-60%) | .tar.gz 또는 .tgz | 빠른 백업 |
| tar cjf | bzip2 압축 | 느림 | 많음 | 높음 (40-70%) | .tar.bz2 | (잘 안쓰임 / 장기 보관용) | 
| tar cJf | xz 압축 | 매우 느림 | 매우 많음 | 매우 높음 (50-80%) | .tar.xz | 장기 보관 |

- **기본 tar (cf)**: 단순히 여러 파일을 하나로 묶기만 함 (아카이브)
- **tar + 압축 (czf, cjf, cJf)**: 묶은 후 실제 압축 알고리즘 적용
- **압축률**: 파일 종류에 따라 차이가 크며, 텍스트 파일은 더 높은 압축률을 보임
- **용도 추천**: 
  - 빠른 백업: `tar czf` (gzip)
  - 장기 보관: `tar cJf` (xz)
  - 단순 묶기: `tar cf`

이 방식으로 최종 cicd 구문을 적용하여 메모리, 디스크 사용량을 대폭 감소 시킬 수 있었고, 이에 따라 빌드 시간도 단축할 수 있었다.

개선 지표를 확인하기 위해 디버그 구분도 적용해서 모니터링 해보았다.

<details>
<summary>메모리 사용량 모니터링 로그</summary>

EC2 서버 업로드 시 메모리 사용량 (약 30mb 사용 / Peak)
```
[DEBUG][GHA] 🔍 복사 전 EC2 메모리: 586Mi/914Mi
[MONITOR] 03:50:57 - 메모리: 580MB/914MB (63.4%)
[MONITOR] 03:50:58 - 메모리: 580MB/914MB (63.4%)
[MONITOR] 03:50:59 - 메모리: 580MB/914MB (63.4%)
[MONITOR] 03:51:00 - 메모리: 580MB/914MB (63.4%)
[MONITOR] 03:51:01 - 메모리: 572MB/914MB (62.5%)
[MONITOR] 03:51:02 - 메모리: 577MB/914MB (63.1%)
[MONITOR] 03:51:03 - 메모리: 583MB/914MB (63.7%)
[MONITOR] 03:51:04 - 메모리: 583MB/914MB (63.7%)
[MONITOR] 03:51:05 - 메모리: 602MB/914MB (65.8%)
[MONITOR] 03:51:06 - 메모리: 599MB/914MB (65.5%)
[MONITOR] 03:51:07 - 메모리: 597MB/914MB (65.3%)
[MONITOR] 03:51:08 - 메모리: 592MB/914MB (64.7%)
[MONITOR] 03:51:09 - 메모리: 594MB/914MB (64.9%)
[MONITOR] 03:51:10 - 메모리: 591MB/914MB (64.6%)
[MONITOR] 03:51:11 - 메모리: 591MB/914MB (64.6%)
[MONITOR] 03:51:12 - 메모리: 591MB/914MB (64.6%)
[MONITOR] 03:51:13 - 메모리: 592MB/914MB (64.7%)
[MONITOR] 03:51:15 - 메모리: 592MB/914MB (64.7%)
[MONITOR] 03:51:16 - 메모리: 592MB/914MB (64.7%)
[MONITOR] 03:51:17 - 메모리: 592MB/914MB (64.7%)
[MONITOR] 03:51:18 - 메모리: 578MB/914MB (63.2%)
[MONITOR] 03:51:19 - 메모리: 578MB/914MB (63.2%)
[MONITOR] 03:51:20 - 메모리: 578MB/914MB (63.2%)
[MONITOR] 03:51:21 - 메모리: 578MB/914MB (63.2%)
[DEBUG][GHA] 🔍 복사 후 EC2 메모리: 572Mi/914Mi
```

EC2 서버에서 압축해제 시 메모리 사용량(약 60MB 사용 / Peak)
```
[DEBUG][EC2] 🔍 압축 해제 전 메모리: 334Mi/914Mi
[MONITOR] 03:51:28 - 메모리: 334MB/914MB (36.5%)
[MONITOR] 03:51:29 - 메모리: 408MB/914MB (44.6%)
[MONITOR] 03:51:30 - 메모리: 341MB/914MB (37.3%)
[MONITOR] 03:51:31 - 메모리: 318MB/914MB (34.7%)
[MONITOR] 03:51:32 - 메모리: 319MB/914MB (34.9%)
[MONITOR] 03:51:33 - 메모리: 317MB/914MB (34.6%)
[MONITOR] 03:51:34 - 메모리: 328MB/914MB (35.8%)
[MONITOR] 03:51:35 - 메모리: 343MB/914MB (37.5%)
[MONITOR] 03:51:36 - 메모리: 343MB/914MB (37.5%)
[MONITOR] 03:51:37 - 메모리: 343MB/914MB (37.5%)
[DEBUG][EC2] 🔍 압축 해제 후 메모리: 343Mi/914Mi
```

</details>

<details>
<summary>디스크 사용량</summary>

```
====================== 📦 패키징 정보 ======================
Full node_modules size         | 929M
Production node_modules size   | 563M
Deploy package size            | 791M
Final compressed size          | 176M
=============================================================
```

</details>

최종 개선 지표

| 항목 | 개선 전 | 개선 후 | 개선 지표 |
|---|---|---|---|
|메모리 사용량(Peak) | 400MB 이상 | 약 40MB | 약 90% 감소 |
|디스크 사용량(Peak) | 약 1.2GB | 약 790MB | 약 35% 감소 |
|배포 시간 | 3분 이상 | 2분 30초 내외 | 약 20% 감소 |

마지막 문제는 https 적용이었다.

aws 기본 url을 사용하면 자동으로 https까지 적용되지만, 나는 도메인을 구매했기 때문에 직접 https 연동까지 해줘야했다.

aws에서 ACM(AWS Certificate Manager)를 통해 인증서를 발급받을 수 있긴 하지만 무료로 사용하려면 AWS 내부에서만 사용가능하고 인증서 파일을 다운로드 받지 못한다는 문제가 있었다.
CloudFront, ALB등에서만 사용가능한데 ALB는 유료이고, CloudFront는 cdn이기 때문에 EC2 환경과는 잘 맞지 않았다.(해당 트러블 슈팅은 추후에 등록 예정)

그래서 인증서에 대해 좀 더 알아보았는데, Let's Encrypt 라는 비영리 기관에서 인증서를 무료로 발급해준다는 것을 알았다.
유효기간이 3개월로 짧지만, 주기적 재발급 로직을 적용한다면 사용하는데 문제는 없을 듯 했다.

여기에 nginx config 까지 도입하여 http 접속시 https로 redirect 하는 구문과 인증서를 붙여주는 작업까지 적용해 https 적용을 구현할 수 있었다.
